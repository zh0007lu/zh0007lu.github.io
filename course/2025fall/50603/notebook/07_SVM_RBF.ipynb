{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Use if you run the notebook on Google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qPtUAnJYkjo",
        "outputId": "46c44cd0-5830-422f-9120-1171a3d6ca9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mglearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipx8mVkTYlOO",
        "outputId": "8c32f877-94e3-4ccd-be75-db2030c16149"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mglearn\n",
            "  Downloading mglearn-0.2.0-py2.py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mglearn) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mglearn) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from mglearn) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from mglearn) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from mglearn) (11.3.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from mglearn) (0.12.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from mglearn) (2.37.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from mglearn) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mglearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->mglearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->mglearn) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->mglearn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->mglearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.17.0)\n",
            "Downloading mglearn-0.2.0-py2.py3-none-any.whl (581 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mglearn\n",
            "Successfully installed mglearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oti3v2LyYj0K"
      },
      "source": [
        "# 7: RBF SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIpKdFc1Yj0N"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7zognNzDYj0N",
        "outputId": "391d74dc-a23c-4539-e04d-d659167c0bcf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2300448330.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/50603/code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/50603'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import Image, HTML\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/50603/code\")\n",
        "os.chdir('/content/drive/MyDrive/50603')\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import mglearn\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact, interactive\n",
        "from plotting_functions import *\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "from utils import *\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMk-z_9IYj0P"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "C82US9PeYj0P"
      },
      "source": [
        "## Support Vector Machines (SVMs) with RBF kernel [[video](https://youtu.be/ic_zqOhi020)]\n",
        "\n",
        "- Very high-level overview\n",
        "- Our goals here are\n",
        "    - Use `scikit-learn`'s SVM model.\n",
        "    - Broadly explain the notion of support vectors.  \n",
        "    - Explain how `C` and `gamma` hyperparameters control the fundamental tradeoff.\n",
        "    \n",
        "> (Optional) RBF stands for radial basis functions. We won't go into what it means here. Refer to [this video](https://www.youtube.com/watch?v=Qc5IyLW_hns) if you want to know more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02WXORbrYj0Q"
      },
      "source": [
        "### Overview\n",
        "\n",
        "- SVM RBFs **only remember the key examples (*support vectors*)**\n",
        "- The decision boundary is defined by **a set of positive and negative examples** and **their weights** together with **their similarity measure**\n",
        "- Different kernel functions can be used but a popular kernel is Radial Basis Functions (RBFs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QaqV951Yj0Q"
      },
      "source": [
        "### Let's explore SVM RBFs\n",
        "\n",
        "Let's try SVMs on the cities dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv6HR4yQYj0R"
      },
      "outputs": [],
      "source": [
        "cities_df = pd.read_csv(\"data/canada_usa_cities.csv\")\n",
        "X_cities = cities_df[[\"longitude\", \"latitude\"]]\n",
        "y_cities = cities_df[\"country\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IPDP_9JYj0R"
      },
      "outputs": [],
      "source": [
        "mglearn.discrete_scatter(X_cities.iloc[:, 0], X_cities.iloc[:, 1], y_cities)\n",
        "plt.xlabel(\"longitude\")\n",
        "plt.ylabel(\"latitude\")\n",
        "plt.legend(loc=1);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVNC7eCQYj0S"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_cities, y_cities, test_size=0.2, random_state=123\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Dc2bpU5Yj0S"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(gamma=0.01)  # Ignore gamma for now\n",
        "scores = cross_validate(svm, X_train, y_train, return_train_score=True)\n",
        "print(\"SVC Mean validation score %0.3f\" % (np.mean(scores[\"test_score\"])))\n",
        "pd.DataFrame(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBoPIdzrYj0U"
      },
      "source": [
        "### Decision boundary of SVMs\n",
        "- We can think of SVM with RBF kernel as \"smooth KNN\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "L9kfma_aYj0U"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "svm.fit(X_train, y_train)  # Fitting the svm model with the training data\n",
        "mglearn.plots.plot_2d_separator(\n",
        "    svm, X_train.to_numpy(), fill=True, eps=0.5, ax=ax, alpha=0.4\n",
        ")  # Plotting the decision boundary for the svm model\n",
        "mglearn.discrete_scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], y_train, ax=ax)  # Plotting the training data\n",
        "ax.set_title(svm)  # Setting the title to the svm model\n",
        "ax.set_xlabel(\"longitude\")  # Setting the x-label to \"longitude\"\n",
        "ax.set_ylabel(\"latitude\")  # Setting the y-label to \"latitude\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QchjS40qYj0U"
      },
      "source": [
        "### Support vectors\n",
        "\n",
        "- Each training example either is or isn't a \"support vector\".\n",
        "  - This gets decided during `fit`.\n",
        "\n",
        "- **Main insight: the decision boundary only depends on the support vectors.**\n",
        "\n",
        "- Let's look at the support vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "hgceHCNkYj0U"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "n = 20\n",
        "n_classes = 2\n",
        "X_toy, y_toy = make_blobs(\n",
        "    n_samples=n, centers=n_classes, random_state=300\n",
        ")  # Let's generate some fake data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "FzQSoYZMYj0U"
      },
      "outputs": [],
      "source": [
        "mglearn.discrete_scatter(X_toy[:, 0], X_toy[:, 1], y_toy)\n",
        "plt.xlabel(\"Feature 0\")\n",
        "plt.ylabel(\"Feature 1\")\n",
        "svm = SVC(kernel=\"rbf\", C=10, gamma=0.1).fit(X_toy, y_toy)\n",
        "mglearn.plots.plot_2d_separator(svm, X_toy, fill=True, eps=0.5, alpha=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bw5ODbGYj0V"
      },
      "outputs": [],
      "source": [
        "svm.support_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ9ZE69VYj0V"
      },
      "outputs": [],
      "source": [
        "X_toy[svm.support_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjJizaXoYj0V"
      },
      "outputs": [],
      "source": [
        "mglearn.plots.plot_2d_separator(svm, X_toy, fill=True, eps=0.5, alpha=0.4)\n",
        "plot_support_vectors(svm, X_toy, y_toy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahq0tCy6Yj0V"
      },
      "source": [
        "The support vectors are the bigger points in the plot above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZBhwmzfYj0V"
      },
      "source": [
        "### Hyperparameters of SVM\n",
        "\n",
        "- Key hyperparameters of `rbf` SVM are\n",
        "    - `gamma`\n",
        "    - `C`\n",
        "    \n",
        "- We are not equipped to understand the meaning of these parameters at this point but you are expected to describe **their relation to the fundamental tradeoff**.\n",
        "\n",
        "Optionally, see [`scikit-learn`'s explanation of RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmJCjl05Yj0W"
      },
      "source": [
        "### Relation of `gamma` and the fundamental trade-off\n",
        "\n",
        "- `gamma` controls the complexity (fundamental trade-off), just like other hyperparameters we've seen.\n",
        "  - larger `gamma` $\\rightarrow$ more complex\n",
        "  - smaller `gamma` $\\rightarrow$ less complex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4ey3fSCYj0W"
      },
      "outputs": [],
      "source": [
        "gamma = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
        "plot_svc_gamma(\n",
        "    gamma,\n",
        "    X_train.to_numpy(),\n",
        "    y_train.to_numpy(),\n",
        "    x_label=\"longitude\",\n",
        "    y_label=\"latitude\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2LSKG0RYj0W"
      },
      "source": [
        "### Relation of `C` and the fundamental trade-off\n",
        "\n",
        "- `C` _also_ affects the fundamental tradeoff\n",
        "    - larger `C` $\\rightarrow$ more complex\n",
        "    - smaller `C` $\\rightarrow$ less complex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzZKUTtsYj0W"
      },
      "outputs": [],
      "source": [
        "C = [0.1, 1.0, 100.0, 1000.0, 100000.0]\n",
        "plot_svc_C(\n",
        "    C, X_train.to_numpy(), y_train.to_numpy(), x_label=\"longitude\", y_label=\"latitude\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elN-gaV8Yj0W"
      },
      "source": [
        "### Search over multiple hyperparameters\n",
        "\n",
        "- So far you have seen how to carry out search over a hyperparameter\n",
        "- In the above case the best training error is achieved by the most complex model (large `gamma`, large `C`).\n",
        "- Best validation error requires a hyperparameter search to balance the fundamental tradeoff.\n",
        "  - In general we can't search them one at a time.\n",
        "  - You may look up the following:\n",
        "    - [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "    - [sklearn.model_selection.RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_nsEASkYj0W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "ml2023fall",
      "language": "python",
      "name": "ml2023fall"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}