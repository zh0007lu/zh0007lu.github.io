{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Use if you run the notebook on Google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "eqPPvrPP5tkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mglearn"
      ],
      "metadata": {
        "id": "6X0_HdeM5vsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnwVDTS35rON"
      },
      "source": [
        "# 4: Classification Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECOwdRR_5rOP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:42.290437Z",
          "iopub.status.busy": "2023-05-30T08:41:42.290086Z",
          "iopub.status.idle": "2023-05-30T08:41:46.702766Z",
          "shell.execute_reply": "2023-05-30T08:41:46.700588Z",
          "shell.execute_reply.started": "2023-05-30T08:41:42.290412Z"
        },
        "id": "GKI5AFT15rOQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/50603/code\")\n",
        "os.chdir('/content/drive/MyDrive/50603')\n",
        "\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import mglearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import Image, HTML, display\n",
        "from plotting_functions import *\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from utils import *\n",
        "\n",
        "%matplotlib inline\n",
        "pd.set_option(\"display.max_colwidth\", 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:46.707143Z",
          "iopub.status.busy": "2023-05-30T08:41:46.705110Z",
          "iopub.status.idle": "2023-05-30T08:41:46.712383Z",
          "shell.execute_reply": "2023-05-30T08:41:46.711101Z",
          "shell.execute_reply.started": "2023-05-30T08:41:46.707114Z"
        },
        "id": "97hJAAFS5rOT"
      },
      "outputs": [],
      "source": [
        "# Changing global matplotlib settings for confusion matrix.\n",
        "plt.rcParams[\"xtick.labelsize\"] = 18\n",
        "plt.rcParams[\"ytick.labelsize\"] = 18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEwhpdqt5rOU"
      },
      "source": [
        "## Learning outcomes\n",
        "\n",
        "From this lecture, students are expected to be able to:\n",
        "\n",
        "- Explain why accuracy is not always the best metric in ML.\n",
        "- Explain components of a confusion matrix.\n",
        "- Define precision, recall, and f1-score and use them to evaluate different classifiers.\n",
        "- Interpret and use ROC curves and ROC AUC using `scikit-learn`.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H0wTT_A5rOV"
      },
      "source": [
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbU1fLlZ5rOW"
      },
      "source": [
        "## Evaluation metrics for binary classification: Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQeXN1GP5rOX"
      },
      "source": [
        "### Dataset for demonstration\n",
        "\n",
        "- Let's classify fraudulent and non-fraudulent transactions using Kaggle's [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:46.714997Z",
          "iopub.status.busy": "2023-05-30T08:41:46.713648Z",
          "iopub.status.idle": "2023-05-30T08:41:51.589986Z",
          "shell.execute_reply": "2023-05-30T08:41:51.588748Z",
          "shell.execute_reply.started": "2023-05-30T08:41:46.714958Z"
        },
        "id": "K-AOV0ZL5rOY"
      },
      "outputs": [],
      "source": [
        "cc_df = pd.read_csv(\"data/creditcard.csv\", encoding=\"latin-1\")\n",
        "train_df, test_df = train_test_split(cc_df, test_size=0.3, random_state=111)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:51.592331Z",
          "iopub.status.busy": "2023-05-30T08:41:51.591794Z",
          "iopub.status.idle": "2023-05-30T08:41:51.601951Z",
          "shell.execute_reply": "2023-05-30T08:41:51.600017Z",
          "shell.execute_reply.started": "2023-05-30T08:41:51.592293Z"
        },
        "id": "f149acC55rOa"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "grqRwQXD5rOb"
      },
      "source": [
        "- Good size dataset\n",
        "- For confidentially reasons, it only provides transformed features with PCA, which is a popular dimensionality reduction technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMK47wxo5rOb"
      },
      "source": [
        "### Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:51.603959Z",
          "iopub.status.busy": "2023-05-30T08:41:51.603530Z",
          "iopub.status.idle": "2023-05-30T08:41:51.631445Z",
          "shell.execute_reply": "2023-05-30T08:41:51.630377Z",
          "shell.execute_reply.started": "2023-05-30T08:41:51.603927Z"
        },
        "id": "sgnnOth15rOc"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:51.632936Z",
          "iopub.status.busy": "2023-05-30T08:41:51.632645Z",
          "iopub.status.idle": "2023-05-30T08:41:52.082116Z",
          "shell.execute_reply": "2023-05-30T08:41:52.080600Z",
          "shell.execute_reply.started": "2023-05-30T08:41:51.632909Z"
        },
        "tags": [],
        "id": "8JgsxyRp5rOd"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:52.087042Z",
          "iopub.status.busy": "2023-05-30T08:41:52.086606Z",
          "iopub.status.idle": "2023-05-30T08:41:52.570196Z",
          "shell.execute_reply": "2023-05-30T08:41:52.568887Z",
          "shell.execute_reply.started": "2023-05-30T08:41:52.087012Z"
        },
        "tags": [],
        "id": "PmvdbRUD5rOd"
      },
      "outputs": [],
      "source": [
        "# no missing data as all columns have same count:\n",
        "train_df.describe().loc[\"count\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI3L_uWi5rOd"
      },
      "source": [
        "- We do not have categorical features. All features are numeric.\n",
        "- We have to be careful about the `Time` and `Amount` features.\n",
        "- We could scale `Amount`.\n",
        "- Do we want to scale time?\n",
        "    - In this lecture we'll do it's probably not the best thing to do.\n",
        "    - We'll learn about time series briefly later in the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdGUCOE55rOd"
      },
      "source": [
        "Let's separate `X` and `y` for train and test splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:52.572706Z",
          "iopub.status.busy": "2023-05-30T08:41:52.572042Z",
          "iopub.status.idle": "2023-05-30T08:41:52.609911Z",
          "shell.execute_reply": "2023-05-30T08:41:52.606849Z",
          "shell.execute_reply.started": "2023-05-30T08:41:52.572652Z"
        },
        "id": "EmOJIu_F5rOe"
      },
      "outputs": [],
      "source": [
        "X_train_big, y_train_big = train_df.drop(columns=[\"Class\"]), train_df[\"Class\"]\n",
        "X_test, y_test = test_df.drop(columns=[\"Class\"]), test_df[\"Class\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_5i3T_5rOe"
      },
      "source": [
        "- It's **easier to demonstrate** evaluation metrics using an explicit **validation set instead of using cross-validation**.\n",
        "- So let's create a validation set.\n",
        "- Our data is large enough so it shouldn't be a problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:52.614761Z",
          "iopub.status.busy": "2023-05-30T08:41:52.614292Z",
          "iopub.status.idle": "2023-05-30T08:41:52.699309Z",
          "shell.execute_reply": "2023-05-30T08:41:52.697484Z",
          "shell.execute_reply.started": "2023-05-30T08:41:52.614717Z"
        },
        "id": "WCZL-q0I5rOe"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_big, y_train_big, test_size=0.3, random_state=123\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQwKnGy5rOf"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT8dmocv5rOf"
      },
      "source": [
        "Let's try `LogisticRegression`. Don't worry about the logistic regression for now. It is a simple and widely used classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:41:52.957182Z",
          "iopub.status.busy": "2023-05-30T08:41:52.956481Z",
          "iopub.status.idle": "2023-05-30T08:42:04.744603Z",
          "shell.execute_reply": "2023-05-30T08:42:04.742148Z",
          "shell.execute_reply.started": "2023-05-30T08:41:52.957132Z"
        },
        "id": "wdjKnLdY5rOf"
      },
      "outputs": [],
      "source": [
        "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "pd.DataFrame(cross_validate(pipe_lr, X_train, y_train, return_train_score=True)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3P037eK5rOf"
      },
      "source": [
        "- `.score` by default returns accuracy which is\n",
        "$$accuracy = \\frac{correct\\ predictions}{total\\ examples}$$\n",
        "- Is accuracy a good metric here?\n",
        "- Is there anything more informative than accuracy that we can use here?\n",
        "\n",
        "Let's dig a little deeper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqOh92zh5rOg"
      },
      "source": [
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9umSTNt5rOg"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QMlAdJj5rOg"
      },
      "source": [
        "One way to get a better understanding of the errors is by looking at\n",
        "- false positives (type I errors), where the model incorrectly spots examples as fraud\n",
        "- false negatives (type II errors), where it's missing to spot fraud examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:04.761502Z",
          "iopub.status.busy": "2023-05-30T08:42:04.760357Z",
          "iopub.status.idle": "2023-05-30T08:42:07.128723Z",
          "shell.execute_reply": "2023-05-30T08:42:07.127150Z",
          "shell.execute_reply.started": "2023-05-30T08:42:04.761412Z"
        },
        "tags": [],
        "id": "wrPQAUMx5rOh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "disp = ConfusionMatrixDisplay.from_estimator(\n",
        "    pipe_lr,\n",
        "    X_valid,\n",
        "    y_valid,\n",
        "    display_labels=[\"Non fraud\", \"fraud\"],\n",
        "    values_format=\"d\",\n",
        "    cmap=plt.cm.Blues,\n",
        "    colorbar=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:07.134830Z",
          "iopub.status.busy": "2023-05-30T08:42:07.134379Z",
          "iopub.status.idle": "2023-05-30T08:42:07.580187Z",
          "shell.execute_reply": "2023-05-30T08:42:07.578720Z",
          "shell.execute_reply.started": "2023-05-30T08:42:07.134797Z"
        },
        "id": "x-bOgPhd5rOh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predictions = pipe_lr.predict(X_valid)\n",
        "TN, FP, FN, TP = confusion_matrix(y_valid, predictions).ravel()\n",
        "plot_confusion_matrix_example(TN, FP, FN, TP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0C1hrE-5rOh"
      },
      "source": [
        "- **Perfect** prediction has all values **down the diagonal**\n",
        "- **Off diagonal** entries can often tell us about what is being **mis-predicted**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tndx6_-w5rOi"
      },
      "source": [
        "### What is \"positive\" and \"negative\"?\n",
        "\n",
        "- Two kinds of binary classification problems\n",
        "    - Distinguishing between two classes\n",
        "    - **Spotting** a class (spot fraud transaction, spot spam, spot disease)\n",
        "- In case of spotting problems, the thing that we are interested in spotting is considered \"**positive**\".\n",
        "- Above we wanted to **spot fraudulent** transactions and so they are \"positive\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA1yjxr35rOi"
      },
      "source": [
        "You can get a numpy array of confusion matrix, and you can *unpack* it into its elements using numpy `ravel()` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:07.582730Z",
          "iopub.status.busy": "2023-05-30T08:42:07.582328Z",
          "iopub.status.idle": "2023-05-30T08:42:07.632774Z",
          "shell.execute_reply": "2023-05-30T08:42:07.627275Z",
          "shell.execute_reply.started": "2023-05-30T08:42:07.582700Z"
        },
        "tags": [],
        "id": "CcTCMaPQ5rOi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predictions = pipe_lr.predict(X_valid)  # note that pipe_lr must have already been fitted using train data\n",
        "cm = confusion_matrix(y_valid, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:07.636497Z",
          "iopub.status.busy": "2023-05-30T08:42:07.635482Z",
          "iopub.status.idle": "2023-05-30T08:42:07.648226Z",
          "shell.execute_reply": "2023-05-30T08:42:07.647177Z",
          "shell.execute_reply.started": "2023-05-30T08:42:07.636453Z"
        },
        "tags": [],
        "id": "6qwL_zse5rOi"
      },
      "outputs": [],
      "source": [
        "print(\"Confusion matrix for fraud dataset:\")\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:07.650356Z",
          "iopub.status.busy": "2023-05-30T08:42:07.649565Z",
          "iopub.status.idle": "2023-05-30T08:42:07.685781Z",
          "shell.execute_reply": "2023-05-30T08:42:07.683913Z",
          "shell.execute_reply.started": "2023-05-30T08:42:07.650318Z"
        },
        "tags": [],
        "id": "NpRL9Z1O5rOj"
      },
      "outputs": [],
      "source": [
        "cm.ravel()  # get a flattened array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:07.689446Z",
          "iopub.status.busy": "2023-05-30T08:42:07.688404Z",
          "iopub.status.idle": "2023-05-30T08:42:07.727571Z",
          "shell.execute_reply": "2023-05-30T08:42:07.723762Z",
          "shell.execute_reply.started": "2023-05-30T08:42:07.689401Z"
        },
        "tags": [],
        "id": "u3oDc80G5rOj"
      },
      "outputs": [],
      "source": [
        "TN, FP, FN, TP = cm.ravel()  # unpack cm elements\n",
        "TN, FP, FN, TP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmJfKm_A5rOk"
      },
      "source": [
        "### Confusion matrix with cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrllXph65rOk"
      },
      "source": [
        "- You can also calculate confusion matrix with cross-validation using the `cross_val_predict` method.\n",
        "- Then you need to use `ConfusionMatrixDisplay`'s **`from_predictions`** to draw confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:07.731821Z",
          "iopub.status.busy": "2023-05-30T08:42:07.730422Z",
          "iopub.status.idle": "2023-05-30T08:42:16.142697Z",
          "shell.execute_reply": "2023-05-30T08:42:16.140660Z",
          "shell.execute_reply.started": "2023-05-30T08:42:07.731736Z"
        },
        "id": "MhG9Ocu25rOk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "confusion_matrix(y_train, cross_val_predict(pipe_lr, X_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:16.146899Z",
          "iopub.status.busy": "2023-05-30T08:42:16.145975Z",
          "iopub.status.idle": "2023-05-30T08:42:25.668859Z",
          "shell.execute_reply": "2023-05-30T08:42:25.666848Z",
          "shell.execute_reply.started": "2023-05-30T08:42:16.146853Z"
        },
        "id": "hxgqxZgC5rOv"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_train,\n",
        "    cross_val_predict(pipe_lr, X_train, y_train),\n",
        "    display_labels=[\"Non fraud\", \"fraud\"],\n",
        "    values_format=\"d\",\n",
        "    cmap=plt.cm.Blues,\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hUNA-1w5rOv"
      },
      "source": [
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ms7pYR35rOv"
      },
      "source": [
        "## Precision, recall, f1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oxu684k5rOw"
      },
      "source": [
        "- We have been using `.score` to assess our models, which returns **accuracy by default**.\n",
        "- Accuracy is misleading when we have class imbalance.\n",
        "- We need other metrics to assess our models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKetMRLN5rOw"
      },
      "source": [
        "- We'll discuss three commonly used metrics which are **based on confusion matrix**:\n",
        "    - *recall*\n",
        "    - *precision*\n",
        "    - *f1 score*\n",
        "- Note that these metrics will only help us **assessing our model**.\n",
        "- Later we'll talk about a few ways to address class imbalance problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:25.678271Z",
          "iopub.status.busy": "2023-05-30T08:42:25.677859Z",
          "iopub.status.idle": "2023-05-30T08:42:28.449046Z",
          "shell.execute_reply": "2023-05-30T08:42:28.447067Z",
          "shell.execute_reply.started": "2023-05-30T08:42:25.678244Z"
        },
        "tags": [],
        "id": "JeQQD58P5rOw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "predictions = pipe_lr.predict(X_valid)\n",
        "cm = confusion_matrix(y_valid, predictions)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "print(\"TN, FP, FN, TP:\", TN, FP, FN, TP, '\\n')\n",
        "cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgVlx-qk5rOx"
      },
      "source": [
        "### Recall\n",
        "\n",
        "Among all positive examples, how many did you identify?\n",
        "$$ recall = \\frac{TP}{TP+FN} = \\frac{TP}{\\#positives} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:28.467603Z",
          "iopub.status.busy": "2023-05-30T08:42:28.464101Z",
          "iopub.status.idle": "2023-05-30T08:42:28.918436Z",
          "shell.execute_reply": "2023-05-30T08:42:28.916574Z",
          "shell.execute_reply.started": "2023-05-30T08:42:28.467516Z"
        },
        "id": "J4yB8F8U5rOx"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(\n",
        "    pipe_lr,\n",
        "    X_valid,\n",
        "    y_valid,\n",
        "    display_labels=[\"Non fraud\", \"fraud\"],\n",
        "    values_format=\"d\",\n",
        "    cmap=plt.cm.Blues,\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:28.920620Z",
          "iopub.status.busy": "2023-05-30T08:42:28.920238Z",
          "iopub.status.idle": "2023-05-30T08:42:28.929355Z",
          "shell.execute_reply": "2023-05-30T08:42:28.927854Z",
          "shell.execute_reply.started": "2023-05-30T08:42:28.920589Z"
        },
        "id": "AbR4pejy5rOx"
      },
      "outputs": [],
      "source": [
        "print(\"TP = %0.4f, FN = %0.4f\" % (TP, FN))\n",
        "recall = TP / (TP + FN)\n",
        "print(\"Recall: %0.4f\" % (recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e25ofcG5rOx"
      },
      "source": [
        "### Precision\n",
        "\n",
        "Among the positive examples you identified, how many were actually positive?\n",
        "\n",
        "$$ precision = \\frac{TP}{TP+FP}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:28.931140Z",
          "iopub.status.busy": "2023-05-30T08:42:28.930783Z",
          "iopub.status.idle": "2023-05-30T08:42:29.370078Z",
          "shell.execute_reply": "2023-05-30T08:42:29.368562Z",
          "shell.execute_reply.started": "2023-05-30T08:42:28.931111Z"
        },
        "id": "d8i_n_BH5rOy"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_estimator(\n",
        "    pipe_lr,\n",
        "    X_valid,\n",
        "    y_valid,\n",
        "    display_labels=[\"Non fraud\", \"fraud\"],\n",
        "    values_format=\"d\",\n",
        "    cmap=plt.cm.Blues,\n",
        ");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.372233Z",
          "iopub.status.busy": "2023-05-30T08:42:29.371718Z",
          "iopub.status.idle": "2023-05-30T08:42:29.381809Z",
          "shell.execute_reply": "2023-05-30T08:42:29.379916Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.372203Z"
        },
        "id": "gOUOXuIR5rOy"
      },
      "outputs": [],
      "source": [
        "print(\"TP = %0.4f, FP = %0.4f\" % (TP, FP))\n",
        "precision = TP / (TP + FP)\n",
        "print(\"Precision: %0.4f\" % (precision))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_w-1P2D5rOy"
      },
      "source": [
        "### F1-score\n",
        "\n",
        "- F1-score **combines precision and recall** to give one score, which could be used in hyperparameter optimization, for instance.\n",
        "- F1-score is a harmonic mean of precision and recall.\n",
        "\n",
        "\n",
        "$$ f1 = 2 \\times \\frac{ precision \\times recall}{precision + recall}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.384524Z",
          "iopub.status.busy": "2023-05-30T08:42:29.384109Z",
          "iopub.status.idle": "2023-05-30T08:42:29.397907Z",
          "shell.execute_reply": "2023-05-30T08:42:29.396510Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.384493Z"
        },
        "id": "j43YBp0B5rOz"
      },
      "outputs": [],
      "source": [
        "print(\"precision: %0.4f\" % (precision))\n",
        "print(\"recall: %0.4f\" % (recall))\n",
        "f1_score = (2 * precision * recall) / (precision + recall)\n",
        "print(\"f1: %0.4f\" % (f1_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XenWelO65rOz"
      },
      "source": [
        "Let's look at all metrics at once on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.399992Z",
          "iopub.status.busy": "2023-05-30T08:42:29.399567Z",
          "iopub.status.idle": "2023-05-30T08:42:29.418862Z",
          "shell.execute_reply": "2023-05-30T08:42:29.417314Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.399960Z"
        },
        "id": "glhI1HUT5rOz"
      },
      "outputs": [],
      "source": [
        "## Calculate evaluation metrics by ourselves\n",
        "data = {\n",
        "    \"calculation\": [],\n",
        "    \"accuracy\": [],\n",
        "    \"error\": [],\n",
        "    \"precision\": [],\n",
        "    \"recall\": [],\n",
        "    \"f1 score\": [],\n",
        "}\n",
        "data[\"calculation\"].append(\"manual\")\n",
        "data[\"accuracy\"].append((TP + TN) / (TN + FP + FN + TP))\n",
        "data[\"error\"].append((FP + FN) / (TN + FP + FN + TP))\n",
        "data[\"precision\"].append(precision)  # TP / (TP + FP)\n",
        "data[\"recall\"].append(recall)  # TP / (TP + FN)\n",
        "data[\"f1 score\"].append(f1_score)  # (2 * precision * recall) / (precision + recall)\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-k4ap15rO0"
      },
      "source": [
        "- `scikit-learn` has functions for [these metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.420621Z",
          "iopub.status.busy": "2023-05-30T08:42:29.420271Z",
          "iopub.status.idle": "2023-05-30T08:42:29.730347Z",
          "shell.execute_reply": "2023-05-30T08:42:29.727705Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.420591Z"
        },
        "id": "LaNPnnrD5rO0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "data[\"accuracy\"].append(accuracy_score(y_valid, pipe_lr.predict(X_valid)))\n",
        "data[\"error\"].append(1 - accuracy_score(y_valid, pipe_lr.predict(X_valid)))\n",
        "data[\"precision\"].append(\n",
        "    precision_score(y_valid, pipe_lr.predict(X_valid), zero_division=1)\n",
        ")\n",
        "data[\"recall\"].append(recall_score(y_valid, pipe_lr.predict(X_valid)))\n",
        "data[\"f1 score\"].append(f1_score(y_valid, pipe_lr.predict(X_valid)))\n",
        "data[\"calculation\"].append(\"sklearn\")\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index([\"calculation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew0U7ict5rO0"
      },
      "source": [
        "The scores match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kky-njB85rO1"
      },
      "source": [
        "### Classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPIx8QeP5rO1"
      },
      "source": [
        "- There is a convenient function called `classification_report` in `sklearn` which gives this info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.754713Z",
          "iopub.status.busy": "2023-05-30T08:42:29.744341Z",
          "iopub.status.idle": "2023-05-30T08:42:29.780248Z",
          "shell.execute_reply": "2023-05-30T08:42:29.778273Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.754602Z"
        },
        "id": "rpXDhjlx5rO1"
      },
      "outputs": [],
      "source": [
        "pipe_lr.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.787404Z",
          "iopub.status.busy": "2023-05-30T08:42:29.787056Z",
          "iopub.status.idle": "2023-05-30T08:42:29.973021Z",
          "shell.execute_reply": "2023-05-30T08:42:29.972098Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.787375Z"
        },
        "scrolled": true,
        "id": "Ai6tpkwP5rO2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"y_valid, not fraud:\", len(y_valid) - y_valid.sum())\n",
        "print(\"y_valid, fraud:      \", y_valid.sum())\n",
        "print(\"X_valid, total:    \", X_valid.shape[0], \"\\n\\n\")\n",
        "\n",
        "print(classification_report(\n",
        "        y_valid, pipe_lr.predict(X_valid), target_names=[\"non-fraud\", \"fraud\"], digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:29.975109Z",
          "iopub.status.busy": "2023-05-30T08:42:29.974738Z",
          "iopub.status.idle": "2023-05-30T08:42:30.166841Z",
          "shell.execute_reply": "2023-05-30T08:42:30.165190Z",
          "shell.execute_reply.started": "2023-05-30T08:42:29.975079Z"
        },
        "id": "JuSCZqHK5rO2"
      },
      "outputs": [],
      "source": [
        "cr_dict = classification_report(\n",
        "    y_valid, pipe_lr.predict(X_valid), target_names=[\"non-fraud\", \"fraud\"], output_dict=True)\n",
        "\n",
        "cr = pd.DataFrame(cr_dict).T\n",
        "cr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iXJk0I05rO3"
      },
      "source": [
        "### Macro average\n",
        "\n",
        "- You give **equal importance** to all classes and average over all classes.\n",
        "- In the example above, recall for non-fraud is ~ 1.0 and fraud is 0.63, and so macro average is 0.81.\n",
        "- See our example calculation below for `macro avg` for `precision`, `recall`, and `f1-score`\n",
        "- More relevant in case of **multi-class** problems (more later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1smFKbrQ5rO3"
      },
      "source": [
        "### Weighted average\n",
        "\n",
        "- Weighted by the number of samples in each class.\n",
        "- Divide by the total number of samples.\n",
        "- See our example calculation below for `weighted_avg_of_precision`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVSG2Kmh5rO4"
      },
      "source": [
        "### Which one to use?\n",
        "Which one of Weighted or Macro averages is relevant depends upon whether you think:\n",
        "\n",
        "- each class should have the same weight or\n",
        "- each sample should have the same weight.\n",
        "\n",
        "That is, it will be domain/problem dependent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx3XD8N55rO4"
      },
      "source": [
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM1d86Vu5rO4"
      },
      "source": [
        "### Interim summary\n",
        "\n",
        "- **Accuracy is misleading** when you have class **imbalance**.\n",
        "- A **confusion matrix** provides a way to **break down errors** made by our model.\n",
        "- We looked at three metrics based on confusion matrix:\n",
        "    - precision, recall, f1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C67r2wx-5rO5"
      },
      "source": [
        "- Note that what you consider \"positive\" (fraud in our case) is important when calculating precision, recall, and f1-score.\n",
        "- If you flip what is considered positive or negative, we'll end up with different TP, FP, TN, FN, and hence different precision, recall, and f1-scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFAELEdA5rO5"
      },
      "source": [
        "### Evalution metrics overview  \n",
        "There is a lot of terminology here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = 'img/evaluation-metrics.png'\n",
        "display(Image(filename=p, width=1000))"
      ],
      "metadata": {
        "id": "jG5pha6t6NUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erlE4ZsI5rO5"
      },
      "source": [
        "<!-- <img src='./img/evaluation-metrics.png' width=\"1000\" height=\"1000\" /> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CWYgZS25rO6"
      },
      "source": [
        "### Cross validation with different metrics\n",
        "\n",
        "- We can pass different evaluation metrics with `scoring` argument of `cross_validate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:30.332381Z",
          "iopub.status.busy": "2023-05-30T08:42:30.331937Z",
          "iopub.status.idle": "2023-05-30T08:42:42.068085Z",
          "shell.execute_reply": "2023-05-30T08:42:42.066508Z",
          "shell.execute_reply.started": "2023-05-30T08:42:30.332351Z"
        },
        "id": "CuVZLGWN5rO6"
      },
      "outputs": [],
      "source": [
        "scoring = [\n",
        "    \"accuracy\",\n",
        "    \"f1\",\n",
        "    \"recall\",\n",
        "    \"precision\",\n",
        "]  # scoring can be a string, a list, or a dictionary\n",
        "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "scores = cross_validate(\n",
        "    pipe_lr, X_train_big, y_train_big, return_train_score=True, scoring=scoring\n",
        ")\n",
        "pd.DataFrame(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XHKNZMp5rO6"
      },
      "source": [
        "- You can also create [your own scoring function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) and pass it to `cross_validate`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVfk0-TG5rO7"
      },
      "source": [
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BypYQmkf5rO7"
      },
      "source": [
        "## Precision-recall curve and ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNK1wLm45rO8"
      },
      "source": [
        "- Confusion matrix provides a detailed break down of the errors made by the model.\n",
        "- But when creating a confusion matrix, we are using \"hard\" predictions.\n",
        "- Most classifiers in `scikit-learn` provide `predict_proba` method (or `decision_function`) which provides **degree of certainty** about predictions by the classifier.\n",
        "- Can we explore the degree of uncertainty to understand and improve the model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k1Uq_io5rO9"
      },
      "source": [
        "Let's revisit the classification report on our fraud detection example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:42.070513Z",
          "iopub.status.busy": "2023-05-30T08:42:42.070125Z",
          "iopub.status.idle": "2023-05-30T08:42:43.957629Z",
          "shell.execute_reply": "2023-05-30T08:42:43.955590Z",
          "shell.execute_reply.started": "2023-05-30T08:42:42.070482Z"
        },
        "id": "nv907fkB5rO9"
      },
      "outputs": [],
      "source": [
        "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "pipe_lr.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:43.977357Z",
          "iopub.status.busy": "2023-05-30T08:42:43.969905Z",
          "iopub.status.idle": "2023-05-30T08:42:44.196434Z",
          "shell.execute_reply": "2023-05-30T08:42:44.194500Z",
          "shell.execute_reply.started": "2023-05-30T08:42:43.977203Z"
        },
        "id": "O23qpSFR5rO-"
      },
      "outputs": [],
      "source": [
        "y_pred = pipe_lr.predict(X_valid)\n",
        "print(classification_report(y_valid, y_pred, target_names=[\"non-fraud\", \"fraud\"], digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqSeAr8F5rO-"
      },
      "source": [
        "By default, predictions use the **threshold of 0.5**. If `predict_proba` > 0.5, predict \"fraud\" (positive) else predict \"non-fraud\" (negative).\n",
        "\n",
        "\n",
        "In the above code, the function `predict` returns a boolean array, `y_pred`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.198922Z",
          "iopub.status.busy": "2023-05-30T08:42:44.198266Z",
          "iopub.status.idle": "2023-05-30T08:42:44.210926Z",
          "shell.execute_reply": "2023-05-30T08:42:44.208554Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.198851Z"
        },
        "id": "qaHiZtNv5rO-"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.216098Z",
          "iopub.status.busy": "2023-05-30T08:42:44.215326Z",
          "iopub.status.idle": "2023-05-30T08:42:44.227624Z",
          "shell.execute_reply": "2023-05-30T08:42:44.225749Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.216040Z"
        },
        "id": "j9czBTEk5rO_"
      },
      "outputs": [],
      "source": [
        "np.unique(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4syRrmnG5rO_"
      },
      "source": [
        "We can create the same boolean array `y_pred` directly using `predict_proba` > 0.5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.229195Z",
          "iopub.status.busy": "2023-05-30T08:42:44.228857Z",
          "iopub.status.idle": "2023-05-30T08:42:44.446069Z",
          "shell.execute_reply": "2023-05-30T08:42:44.444544Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.229166Z"
        },
        "id": "Tf_tEkaa5rO_"
      },
      "outputs": [],
      "source": [
        "# negative class column is 0, and positive class column is 1, so we want [:, 1]\n",
        "y_pred = pipe_lr.predict_proba(X_valid)[:, 1] > 0.50\n",
        "print(classification_report(y_valid, y_pred, target_names=[\"non-fraud\", \"fraud\"], digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqditeIm5rPA"
      },
      "source": [
        "<br>\n",
        "\n",
        "Now,\n",
        "- Suppose for your business it is more costly to miss fraudulent transactions and you want to achieve a **recall of at least 75%** for the \"fraud\" class.\n",
        "- One way to do this is by **changing the threshold** of `predict_proba`.\n",
        "    - `predict` returns 1 when `predict_proba`'s probabilities are above 0.5 for the \"fraud\" class.\n",
        "\n",
        "**Key idea:**\n",
        "> **what if we _threshold the probability at a smaller value_ so that we identify more examples as \"fraud\" examples?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI3G9MOP5rPB"
      },
      "source": [
        "Let's lower the **threshold to 0.1**. In other words, predict the examples as \"fraud\" if `predict_proba` > 0.1.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.447933Z",
          "iopub.status.busy": "2023-05-30T08:42:44.447550Z",
          "iopub.status.idle": "2023-05-30T08:42:44.492772Z",
          "shell.execute_reply": "2023-05-30T08:42:44.485422Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.447904Z"
        },
        "id": "6os_5UK45rPB"
      },
      "outputs": [],
      "source": [
        "y_pred_lower_threshold = pipe_lr.predict_proba(X_valid)[:, 1] > 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.499404Z",
          "iopub.status.busy": "2023-05-30T08:42:44.498792Z",
          "iopub.status.idle": "2023-05-30T08:42:44.673172Z",
          "shell.execute_reply": "2023-05-30T08:42:44.671789Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.499356Z"
        },
        "scrolled": true,
        "id": "Pt7dxk7l5rPB"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_valid, y_pred_lower_threshold, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnw5fOKA5rPB"
      },
      "source": [
        "### Operating point\n",
        "\n",
        "- Now our recall for \"fraud\" class is >= 0.75.\n",
        "- Setting a **requirement on a classifier** (e.g., recall of >= 0.75) is called setting the **operating point**.\n",
        "- It's usually driven by **business goals** and is useful to make performance guarantees to customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_8uLJ3k5rPC"
      },
      "source": [
        "### Precision/Recall tradeoff\n",
        "\n",
        "- But there is a trade-off between precision and recall.\n",
        "- If you identify more things as \"fraud\",\n",
        "    - recall is going to increase but\n",
        "    - there are likely to be more false positives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWJk_Nm_5rPC"
      },
      "source": [
        "Let's sweep through different thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.675399Z",
          "iopub.status.busy": "2023-05-30T08:42:44.674908Z",
          "iopub.status.idle": "2023-05-30T08:42:44.684457Z",
          "shell.execute_reply": "2023-05-30T08:42:44.682454Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.675348Z"
        },
        "tags": [],
        "id": "pP243_-J5rPC"
      },
      "outputs": [],
      "source": [
        "def f(threshold):\n",
        "    preds = pipe_lr.predict_proba(X_valid)[:, 1] > threshold\n",
        "    print(\"Threshold: \", np.round(threshold,4))\n",
        "    print(\"Precision: \", np.round(precision_score(y_valid, preds),4))\n",
        "    print(\"Recall: \", np.round(recall_score(y_valid, preds), 4))\n",
        "    print(\"f1 score: \", np.round(f1_score(y_valid, preds), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.687177Z",
          "iopub.status.busy": "2023-05-30T08:42:44.686614Z",
          "iopub.status.idle": "2023-05-30T08:42:44.984708Z",
          "shell.execute_reply": "2023-05-30T08:42:44.983322Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.687140Z"
        },
        "tags": [],
        "id": "VVBgW5F05rPC"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive\n",
        "\n",
        "interactive(\n",
        "    f,\n",
        "    threshold=widgets.FloatSlider(min=0, max=0.9, step=0.1, value=0.5),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMPZ1ir45rPD"
      },
      "source": [
        "Let's view Precision and Recall for different thresholds as a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:44.987407Z",
          "iopub.status.busy": "2023-05-30T08:42:44.986135Z",
          "iopub.status.idle": "2023-05-30T08:42:44.997717Z",
          "shell.execute_reply": "2023-05-30T08:42:44.995841Z",
          "shell.execute_reply.started": "2023-05-30T08:42:44.987374Z"
        },
        "tags": [],
        "id": "igermCF15rPD"
      },
      "outputs": [],
      "source": [
        "thresholds = np.arange(0, 1, 0.1)\n",
        "thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:45.000515Z",
          "iopub.status.busy": "2023-05-30T08:42:44.999288Z",
          "iopub.status.idle": "2023-05-30T08:42:46.818189Z",
          "shell.execute_reply": "2023-05-30T08:42:46.816020Z",
          "shell.execute_reply.started": "2023-05-30T08:42:45.000483Z"
        },
        "tags": [],
        "id": "WNcDyHOn5rPE"
      },
      "outputs": [],
      "source": [
        "pr_dict = {\"threshold\": [], \"precision\": [], \"recall\": [], \"f1 score\": []}\n",
        "for threshold in thresholds:\n",
        "    preds = pipe_lr.predict_proba(X_valid)[:, 1] > threshold\n",
        "    pr_dict[\"threshold\"].append(threshold)\n",
        "    pr_dict[\"precision\"].append(precision_score(y_valid, preds))\n",
        "    pr_dict[\"recall\"].append(recall_score(y_valid, preds))\n",
        "    pr_dict[\"f1 score\"].append(f1_score(y_valid, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:46.822360Z",
          "iopub.status.busy": "2023-05-30T08:42:46.820951Z",
          "iopub.status.idle": "2023-05-30T08:42:46.851543Z",
          "shell.execute_reply": "2023-05-30T08:42:46.849400Z",
          "shell.execute_reply.started": "2023-05-30T08:42:46.822317Z"
        },
        "scrolled": true,
        "tags": [],
        "id": "E1PKVU5l5rPE"
      },
      "outputs": [],
      "source": [
        "pr_df = pd.DataFrame(pr_dict).set_index('threshold')\n",
        "pr_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:42:46.855876Z",
          "iopub.status.busy": "2023-05-30T08:42:46.854615Z",
          "iopub.status.idle": "2023-05-30T08:42:47.266682Z",
          "shell.execute_reply": "2023-05-30T08:42:47.264877Z",
          "shell.execute_reply.started": "2023-05-30T08:42:46.855824Z"
        },
        "scrolled": true,
        "id": "IVGgo4kD5rPE"
      },
      "outputs": [],
      "source": [
        "pr_df[['precision', 'recall']].plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKFROU_E5rPF"
      },
      "source": [
        "### Decreasing the threshold\n",
        "\n",
        "- ***Decreasing the threshold*** means a lower bar for predicting fraud.\n",
        "    - You are willing to risk more false positives FP⬆ in exchange of more true positives TP⬆.\n",
        "      - In general, predicted positives (TP + FP)⬆ go up or stay the same\n",
        "      - In general, predicted negatives (TN + FN)⬇ go down or stay the same\n",
        "    - recall is likely to go up or stay the same\n",
        "      - TP⬆ / (TP⬆+FN⬇) so generally recall ⬆\n",
        "    - precision is likely to go down or stay the same\n",
        "      - TP⬆ / (TP⬆+FP⬆) so generally precision ⬇\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yEjr_gq5rPF"
      },
      "source": [
        "### Increasing the threshold\n",
        "\n",
        "On the flip side:\n",
        "\n",
        "- Increasing the threshold means a higher bar for predicting fraud.\n",
        "    - recall would go down or stay the same but precision is likely to go up\n",
        "    - occasionally, precision may go down as the denominator for precision is TP+FP.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8QI07435rPF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ZmZmof5rPF"
      },
      "source": [
        "### Receiver Operating Characteristic (ROC) curve\n",
        "\n",
        "- One commonly used tool to analyze the **behavior of classifiers at different thresholds**.\n",
        "- It considers all possible thresholds for a given classifier given by `predict_proba` and plots false positive rate (FPR) and true positive rate (TPR or recall).\n",
        "$$ FPR  = \\frac{FP}{FP + TN}, TPR = \\frac{TP}{TP + FN}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:07.499524Z",
          "iopub.status.busy": "2023-05-30T08:45:07.499280Z",
          "iopub.status.idle": "2023-05-30T08:45:07.801015Z",
          "shell.execute_reply": "2023-05-30T08:45:07.800014Z",
          "shell.execute_reply.started": "2023-05-30T08:45:07.499506Z"
        },
        "id": "0HYYXfFL5rPG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
        "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR (recall)\")\n",
        "\n",
        "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
        "\n",
        "plt.plot(\n",
        "    fpr[default_threshold],\n",
        "    tpr[default_threshold],\n",
        "    \"or\",\n",
        "    markersize=10,\n",
        "    label=\"threshold 0.5\",\n",
        ")\n",
        "plt.legend(loc=\"best\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abpBgfF95rPG"
      },
      "source": [
        "- The **ideal curve is close to the top left**\n",
        "    - Ideally, you want a classifier with high recall while keeping low false positive rate.  \n",
        "- The red dot corresponds to the **threshold of 0.5**, which is used by predict.\n",
        "- We see that compared to the default threshold, we can achieve a **better recall of around 0.8 without increasing FPR**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zPaUqgH5rPG"
      },
      "source": [
        "#### Let's compare ROC curve of different classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:07.803476Z",
          "iopub.status.busy": "2023-05-30T08:45:07.802974Z",
          "iopub.status.idle": "2023-05-30T08:45:21.058532Z",
          "shell.execute_reply": "2023-05-30T08:45:21.056902Z",
          "shell.execute_reply.started": "2023-05-30T08:45:07.803440Z"
        },
        "tags": [],
        "id": "wEjXywmE5rPG"
      },
      "outputs": [],
      "source": [
        "pipe_svc = make_pipeline(StandardScaler(), SVC())\n",
        "\n",
        "pipe_svc.fit(X_train, y_train)\n",
        "\n",
        "fpr_lr, tpr_lr, thresholds_lr = roc_curve(\n",
        "    y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
        "\n",
        "fpr_svc, tpr_svc, thresholds_svc = roc_curve(\n",
        "    y_valid, pipe_svc.decision_function(X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:21.061836Z",
          "iopub.status.busy": "2023-05-30T08:45:21.061264Z",
          "iopub.status.idle": "2023-05-30T08:45:21.069727Z",
          "shell.execute_reply": "2023-05-30T08:45:21.068006Z",
          "shell.execute_reply.started": "2023-05-30T08:45:21.061761Z"
        },
        "tags": [],
        "id": "HxI0BL8T5rPH"
      },
      "outputs": [],
      "source": [
        "close_default_lr = np.argmin(np.abs(thresholds_lr - 0.5))\n",
        "close_zero_svm = np.argmin(np.abs(thresholds_svc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:21.071799Z",
          "iopub.status.busy": "2023-05-30T08:45:21.071399Z",
          "iopub.status.idle": "2023-05-30T08:45:21.446293Z",
          "shell.execute_reply": "2023-05-30T08:45:21.444973Z",
          "shell.execute_reply.started": "2023-05-30T08:45:21.071761Z"
        },
        "tags": [],
        "id": "llfFriFb5rPH"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr_svc, tpr_svc, label=\"svc\")\n",
        "plt.plot(fpr_lr, tpr_lr, label=\"logistic regression\")\n",
        "plt.plot(\n",
        "    fpr_svc[close_zero_svm],\n",
        "    tpr_svc[close_zero_svm],\n",
        "    \"o\",\n",
        "    markersize=10,\n",
        "    label=\"default threshold svc\",\n",
        "    c=\"b\",\n",
        ")\n",
        "plt.plot(\n",
        "    fpr_lr[close_default_lr],\n",
        "    tpr_lr[close_default_lr],\n",
        "    \"*\",\n",
        "    markersize=10,\n",
        "    label=\"default threshold logistic regression\",\n",
        "    c=\"r\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"False positive rate\")\n",
        "plt.ylabel(\"True positive rate (Recall)\")\n",
        "plt.legend(loc=\"best\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTLUP1gC5rPH"
      },
      "source": [
        "### Area under the curve (AUC)\n",
        "\n",
        "- AUC provides a single meaningful number for the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:21.448265Z",
          "iopub.status.busy": "2023-05-30T08:45:21.447810Z",
          "iopub.status.idle": "2023-05-30T08:45:33.792032Z",
          "shell.execute_reply": "2023-05-30T08:45:33.791090Z",
          "shell.execute_reply.started": "2023-05-30T08:45:21.448237Z"
        },
        "id": "hVjnDCTq5rPH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_lr = roc_auc_score(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
        "roc_svc = roc_auc_score(y_valid, pipe_svc.decision_function(X_valid))\n",
        "print(\"AUC for LR: {:.3f}\".format(roc_lr))\n",
        "print(\"AUC for SVC: {:.3f}\".format(roc_svc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypFtdtLl5rPI"
      },
      "source": [
        "- AUC of **0.5** means **random chance**.\n",
        "- AUC can be interpreted as evaluating the **ranking** of positive examples.\n",
        "- What's the probability that a randomly picked positive point has a higher score according to the classifier than a randomly picked point from the negative class.\n",
        "- AUC of **1.0** means **all positive points have a higher score than all negative points**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PET_FAEY5rPI"
      },
      "source": [
        "***Important***\n",
        "> For classification problems with imbalanced classes, using AP score or AUC is often much more meaningful than using accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKj82bFd5rPI"
      },
      "source": [
        "Similar to `PrecisionRecallCurveDisplay`, there is a `RocCurveDisplay` function in sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:33.793614Z",
          "iopub.status.busy": "2023-05-30T08:45:33.793280Z",
          "iopub.status.idle": "2023-05-30T08:45:34.103022Z",
          "shell.execute_reply": "2023-05-30T08:45:34.101861Z",
          "shell.execute_reply.started": "2023-05-30T08:45:33.793590Z"
        },
        "id": "nIOJMKq55rPJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "RocCurveDisplay.from_estimator(pipe_lr, X_valid, y_valid);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yumxdx7z5rPJ"
      },
      "source": [
        "### Let's look at all the scores at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-30T08:45:34.105658Z",
          "iopub.status.busy": "2023-05-30T08:45:34.105288Z",
          "iopub.status.idle": "2023-05-30T08:45:46.076909Z",
          "shell.execute_reply": "2023-05-30T08:45:46.075641Z",
          "shell.execute_reply.started": "2023-05-30T08:45:34.105630Z"
        },
        "id": "VbHpojZJ5rPJ"
      },
      "outputs": [],
      "source": [
        "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\", \"average_precision\"]\n",
        "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "scores = cross_validate(pipe_lr, X_train_big, y_train_big, scoring=scoring)\n",
        "pd.DataFrame(scores).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ET3SbdY5rPK"
      },
      "source": [
        "***See Also*** (Recommended)\n",
        "> Check out [these visualization](https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation) on ROC and AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndU6FA9d5rPK"
      },
      "source": [
        "<br><br><br><br>"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "ml2023fall",
      "language": "python",
      "name": "ml2023fall"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}